[
  {
    "id": "Robust_Adaptive_MPC",
    "title": "Robust Adaptive MPC",
    "description": "Adaptive Model Predictive Control with statistical guarantees in noisy settings.",
    "fullDescription": "Implements an adaptive MPC controller using MATLAB/Python with noise‑robust performance for autonomous systems.",
    "tags": ["MPC", "Adaptive-Control", "Control Systems", "MATLAB", "Deep Learning", "LSTM"],
    "link": "https://github.com/Muckthebuck/Robust_Adaptive_MPC",
    "githubLink": "https://github.com/Muckthebuck/Robust_Adaptive_MPC"
  },
  {
    "id": "Sokoban-Solver-in-C",
    "title": "Sokoban Solver in C",
    "description": "A Sokoban puzzle solver implementing freeze‑deadlock detection in C.",
    "fullDescription": "C implementation of Sokoban solver using heuristic search and freeze‑deadlock detection to solve levels efficiently.",
    "tags": ["DFS (Depth-First Search)", "Deadlock Detection", "C"],
    "link": "https://github.com/Muckthebuck/Sokoban-Solver-in-C",
    "githubLink": "https://github.com/Muckthebuck/Sokoban-Solver-in-C"
  },
  {
    "id": "AI_PA",
    "title": "AI_PA (Game Search Agent)",
    "description": "A* search algorithm implementation for game agents.",
    "fullDescription": "The first part of an AI project implementing search algorithms for game agents with heuristic optimizations.",
    "tags": ["Python", "A* Search", "Search Algorithms"],
    "link": "https://github.com/Muckthebuck/AI_PA",
    "githubLink": "https://github.com/Muckthebuck/AI_PA"
  },
  {
    "id": "ESI_Project",
    "title": "Study Buddy",
    "description": "Arduino-based time management device using Pomodoro techniques.",
    "fullDescription": "A modular Arduino system integrating timer, LED matrix, buzzer and sensors to create a smart study buddy.",
    "tags": ["Arduino", "Embedded", "Hardware", "C++", "CAD"],
    "link": "https://github.com/Muckthebuck/ESI_Project",
    "githubLink": "https://github.com/Muckthebuck/ESI_Project",
    "bannerImage": "/images/front_panel (2).png"
  },
  {
    "id": "PointNet",
    "title": "PointNet Implementation",
    "description": "Reimplementation of the PointNet architecture for point cloud classification and segmentation.",
    "fullDescription": "Clean from‑scratch implementation of PointNet with Python and PyTorch, maintaining permutation invariance and max‑pooling.",
    "tags": ["Python", "Deep Learning", "Point Cloud", "PyTorch", "Object Classification", "3D Segmentation", "3D Deep Learning", "PointNet"],
    "link": "https://github.com/Muckthebuck/PointNet",
    "githubLink": "https://github.com/Muckthebuck/PointNet"
  },
  {
    "id": "Wasserstein_Image_Morphing",
    "title": "Wasserstein Image Morphing",
    "description": "Image morphing using Wasserstein distance and Optimal Transport paths across RGB channels.",
    "fullDescription": "This project demonstrates smooth morphing between two images by interpolating along the Optimal Transport (OT) path for each RGB channel using the Wasserstein distance. It uses `ott-jax` for efficient Sinkhorn solver implementation and leverages JAX for high-performance numerical computing. The result is a visually coherent transformation that preserves structure across color channels.",
    "githubLink": "https://github.com/Muckthebuck/wasserstein_projection",
    "tags": ["Python","JAX", "ott-jax", "NumPy", "Matplotlib", "scikit-image", "Optimal Transport"],
    "bannerImage": "/images/morph.gif"
  },
  {
    "id": "Portfolio",
    "title": "Portfolio Website",
    "description": "A modular React + TypeScript portfolio website that visualizes projects using a tag-based graph.",
    "fullDescription": "This portfolio website is built with React and TypeScript, showcasing projects in a visually appealing manner using a tag-based graph for navigation.",
    "tags": ["React", "TypeScript", "Portfolio", "Visualization", "Graph Algorithms"],
    "link": "https://muckthebuck.github.io/",
    "githubLink": "https://github.com/Muckthebuck/muckthebuck.github.io"
  },
  {
    "id": "Capstone_Project",
    "title": "Learning Dynamical Systems from a Finite Number of Closed-Loop Trajectories",
    "description": "A research project on learning dynamical systems from closed-loop trajectories using deep learning.",
    "fullDescription": "Model-based control strategies are widely used to regulate dynamical systems, ensuring trajectory tracking and stability. However, these approaches rely on accurate system models, which may not always be available due to unmodeled dynamics, parameter variations, or environmental uncertainties.\n\nThis project investigates the application of the Sign-Perturbed Sums (SPS) algorithm to estimate system dynamics using a finite number of closed-loop data points. The SPS method provides a set of system models with exact probabilistic guarantees that the true system lies within this set. By continuously updating this set in real time with new data, we aim to enhance the robustness and adaptability of control strategies, mitigating performance degradation caused by model uncertainty.\n\nWe developed a modular software architecture that integrates SPS seamlessly into real-time control loops. The architecture supports asynchronous operation, allowing the computationally intensive SPS process to run on a separate processor or device—ideal for distributed systems or embedded applications with limited resources. This design supports flexible deployment across various platforms and simplifies integration with existing controllers.\n\nBy combining real-time SPS-based model updates with robust control synthesis, this project enables adaptive, data-driven closed-loop control. Bayesian methods are employed to fuse SPS confidence regions, refining model estimates over time and improving both safety and performance in dynamic or uncertain environments.\n\nThis framework enhances the reliability of autonomous systems under changing conditions and offers a practical approach for deploying advanced system identification techniques in real-world control applications.\n\nTLDR\nWe estimate how a system behaves using limited data, even when there's noise or uncertainty. Our method gives a guaranteed range of possible models and updates it as more data comes in. This lets us design controllers that stay reliable and safe, even as conditions change.",
    "tags": [
      "System Identification",
      "Dynamical Systems",
      "Research",
      "Python",
      "Kernel Regression",
      "ARMAX",
      "JIT",
      "Optimal Control",
      "Bayesian Methods",
      "Binary Search", 
      "Redis"
    ],
    "githubLink": "https://github.com/Muckthebuck/Learning-Dynamic-Systems",
    "paperLink": "https://github.com/Muckthebuck/Learning-Dynamic-Systems/blob/main/E_21_WERI_009.pdf"
  },
  {
    "id": "bl_localisation",
    "title": "Alternative localisation methods using Bluetooth CTE",
    "description": "Exploring alternative localisation methods using Bluetooth CTE and RSSI.",
    "fullDescription": "This project investigates alternative localisation methods using Bluetooth CTE (Constant Tone Extension) and RSSI (Received Signal Strength Indicator). It explores how beamforming can be combined with CTE for precise positioning and tracking in various applications, leveraging the unique properties of Bluetooth signals to enhance localisation accuracy (within 10cm). The project was done for the University of Melbourne as a Research Assistant on request of an external client. The report and code are therefore not publicly available.",
    "tags": ["Bluetooth", "CTE", "Localisation", "Positioning", "Tracking", "Beamforming", "Embedded", "Research", "Unscented Kalman Filter"]
  },
  {
    "id": "NICEU",
    "title": "NICEU: App to monitor stent based tracheostomy",
    "description": "Android app to monitor a stent-based tracheostomy prototype to minimize neonatal airway damage.",
    "fullDescription": "NICEU is an Android application designed to monitor a stent-based tracheostomy prototype, aiming to minimize airway damage in neonates. The app provides real-time data visualization and alerts for healthcare professionals, enhancing patient safety and care. It was developed as part of a hackathon organized by the University of Melbourne Biomedical Engineering Society (MUBES), where it secured 3rd place.",
    "githubLink": "https://github.com/Muckthebuck/NICEU",
    "tags": ["Android", "Tracheostomy", "Biomedical Engineering", "Hackathon"]
  },
{
  "id": "Underwater_Stereo_Depth",
  "title": "Self-Supervised Underwater Stereo Depth Estimation",
  "description": "A transfer learning pipeline for stereo depth estimation in underwater scenes using self-supervised learning and synthetic labels.",
  "fullDescription": "This project was done under Dr. Ye Pu's supervision from Department of Electrical and Electronics Engineering, University of Melbourne. Acquiring high-quality training data for underwater depth estimation poses numerous challenges, including poor visibility, refraction, and the scarcity of labeled datasets. Moreover, due to the domain gap between in-air and underwater imagery, models trained in air cannot be directly applied to underwater scenarios.\n\nTo tackle this, we introduce a novel transfer learning-based pipeline to fine-tune stereo depth estimation models specifically for underwater environments. Our approach leverages self-supervised learning and generates pseudo-ground-truth stereo pairs using a fine-tuned underwater monocular depth model. By applying synthetic labels—an idea adapted from in-air methods—we convert monocular underwater datasets into usable stereo training data.\n\nThe framework integrates domain-specific enhancements such as underwater data augmentation and color correction to improve performance. To assess generalization, we conducted zero-shot evaluations on four publicly available datasets from FLSea, selecting 100 images from each. Our fine-tuned stereo model demonstrates significantly improved depth resolution and accuracy in these zero-shot tests.\n\nThis project provides a scalable method for underwater stereo depth estimation without requiring expensive data annotation and offers practical value for marine robotics, exploration, and perception tasks in underwater environments.",
  "tags": [
    "Stereo Depth Estimation",
    "Underwater Vision",
    "Transfer Learning",
    "Self-Supervised Learning",
    "Computer Vision",
    "PyTorch",
    "Marine Robotics",
    "3D Perception",
    "Deep Learning",
    "Image Processing",
    "Transformer",
    "Vision Transformer",
    "Research"
  ],
  "githubLink": "https://github.com/Muckthebuck/Self-Supervised-Underwater-Stereo-Depth-Estimation",
  "paperLink": "https://github.com/Muckthebuck/Self-Supervised-Underwater-Stereo-Depth-Estimation/blob/main/11261_physics_informed_knowledge_tra.pdf",
  "bannerImage": "/images/underwater_stereo_depth.png"
},
{
  "id": "SONiC_msft",
  "title": "SONiC (Microsoft Internship)",
  "description": "Contributed to the SONiC project, an open-source network OS for data center switches, by implementing support for the RADIAN feature on T2 hardware.",
  "fullDescription": "During my internship at Microsoft, I contributed to the SONiC (Software for Open Networking in the Cloud) project—an open-source network operating system used in large-scale data center switches. My primary task was to implement support for the RADIAN feature for SONiC on T2 hardware platforms.\n\n\nSpecifically, I added CLI command functionality to manage the `ANCHOR` prefix within the `PREFIX_LIST` table in the `CONFIG_DB`, including support to add and remove anchor prefixes. I designed and implemented YANG model extensions to support the new configuration schema and created the `PrefixListMgr` component to handle real-time configuration changes.\n\nI also introduced two reusable templates (`add_radian` and `del_radian`) to automate the creation and deletion of anchor prefix lists and aggregate addresses.\n\n**Work item tracked:** Microsoft ADO #30112967\n\n**Verification:**\n- Unit tests covering config generation, manager behavior, and YANG model validation\n\nThis contribution improved the flexibility of routing configuration in SONiC and the introduction of `ANCHOR_PREFIX` allowed for faster convergence of routes under multi-fiber cut scenarios.",
  "tags": [
    "Networking",
    "SONiC",
    "Microsoft",
    "Open Source",
    "YANG",
    "Redis",
    "Python",
    "Data Center",
    "Internship"
  ],
  "githubLink": "https://github.com/sonic-net/sonic-buildimage/pull/21732",
  "bannerImage": "/images/SONiC_network_operating_system_logo.jpg"
},
{
  "id": "NoiseResolution-HighDimData",
  "title": "Investigation of Methods for Resolving Statistical Noise and Understanding Correlation Structure in High-Dimensional Data",
  "description": "This project investigates methods for resolving statistical noise and understanding correlation structures in high-dimensional data, with a focus on financial stock return data.",
  "fullDescription": "This project, conducted as part of the ELEN90094 – Large Data Methods & Applications course at The University of Melbourne, investigates methods for resolving statistical noise and understanding correlation structures in high-dimensional data, with a focus on financial stock return data. The analysis is divided into two stages:\n\n1. **Stage 1**: An in-depth study of data analysis methods for identifying true correlation information in complex, high-dimensional datasets. The study involves reviewing and critiquing approaches presented in the research paper by V. Plerou et al. (Physical Review E, 2002), specifically methods for investigating correlation patterns in financial data.\n\n2. **Stage 2**: Application of the methods studied in Stage 1, along with additional methods covered in the course, to real-world financial stock return datasets from periods before and after the emergence of COVID-19. The analysis aims to distinguish true correlations from noise, quantify statistical noise, and reveal structured correlation patterns.\n\nThe project will produce a comprehensive report and code that documents the methods, experiments, and results. The results will provide insights into the dependencies and correlation structures in financial data, and the project will explore the stability and properties of estimated correlation matrices.",
  "tags": [
    "High-Dimensional Data",
    "Statistical Noise",
    "Correlation Structure",
    "Financial Analysis",
    "Python",
    "Data Analysis",
    "Research"
  ],
  "githubLink": "https://github.com/Muckthebuck/NoiseResolution-HighDimData/blob/main/README.md",
  "paperLink": "https://github.com/Muckthebuck/NoiseResolution-HighDimData/blob/main/Final%20report_GroupA.pdf"
},
{
  "id": "catkin_ws",
  "title": "ROS2 Catkin Workspace",
  "description": "A ROS2 Catkin workspace for running SOTA SLAM algorithms using `gazebo`, `rviz2` and `Carla Simulator`.",
  "fullDescription": "This project provides a ROS2 Catkin workspace for running state-of-the-art SLAM (Simultaneous Localization and Mapping) algorithms using `gazebo`, `rviz2`, and the `Carla Simulator`.",
  "tags": [
    "ROS2",
    "CATKIN Workspace",
    "SLAM",
    "Gazebo",
    "Rviz2",
    "Carla Simulator",
    "Robotics",
    "Python",
    "C++",
    "Linux"
  ],
  "githubLink": "https://github.com/Muckthebuck/catkin_ws"
},
{
  "id": "Mobile_Robotics",
  "title": "Autonomous Navigation and Perception in Mobile Robotics (CARLA + ROS)",
  "description": "A full-stack mobile robotics project using CARLA and ROS with A* global path planning and local control via Frenet Planner and MPC.",
  "fullDescription": "This project focuses on autonomous navigation and perception in mobile robotics using the CARLA simulator and the Robot Operating System (ROS). The system implements a complete navigation pipeline for autonomous vehicles, integrating global and local planning, sensor perception, and control modules.\n\n- **Global Path Planning**: Utilizes the A* algorithm to compute an optimal path from a start point to a goal position within the mapped environment.\n- **Local Path Planning**: Implements a Frenet coordinate-based planner to generate feasible local trajectories around dynamic obstacles and road curvature.\n- **Control**: A Model Predictive Controller (MPC) is used for fine-grained trajectory following, ensuring smooth, stable, and constrained motion.\n\nCARLA is used to simulate realistic urban driving scenarios, while ROS nodes handle sensor fusion, decision-making, and planning pipelines. The system enables testing and development of real-time autonomous navigation strategies under realistic conditions.\n\nThis project demonstrates integration of classical planning and control techniques in a modular robotics software stack for autonomous driving applications.",
  "tags": [
    "Mobile Robotics",
    "Autonomous Navigation",
    "Path Planning",
    "Carla Simulator",
    "ROS",
    "A* Search",
    "Frenet Planner",
    "MPC",
    "Control Systems"
  ],
  "githubLink": "https://github.com/Muckthebuck/Mobile_Robotics"
},
{
  "id": "2023-Energy-kit",
  "title": "DNN-LSTM with Hybrid MPC for Home Energy Management System (HEMS)",
  "description": "Integrated predictive control system for energy cost minimization using DNN-LSTM and Hybrid MPC in home energy environments.",
  "fullDescription": "# DNN-LSTM with Hybrid MPC for Home Energy Management System (HEMS)\n\nThis project implements a predictive control framework for optimizing energy use in residential settings. A hybrid system combining Deep Neural Networks (DNN), Long Short-Term Memory (LSTM) models, and Model Predictive Control (MPC) is used to manage battery storage, solar curtailment, and heat pump operations in the presence of variable electricity pricing and weather conditions.\n\n### 🔍 Project Goals\n- Minimize electricity costs in residential homes\n- Maintain stable indoor temperatures\n- Predict solar insolation and temperature for better control decisions\n- Evaluate different pricing scenarios (unidirectional, bidirectional, with penalties)\n\n### ⚙️ Key Components\n- **DNN-LSTM models** for forecasting temperature, load, and solar generation\n- **Hybrid MPC controller** for real-time optimization of control variables\n- **Scenario analysis** across pricing schemes and prediction reliability\n- **Sliding window batches** and online model training pipeline\n\n### 📊 Features\n- Comparative analysis of prediction-aware vs. null prediction cases\n- Real-world weather and load datasets (e.g., BOM, Austin)\n- Structured Jupyter notebooks and Python classes for modularity\n\nThis project was conducted between Mar 2023 – Jul 2023 as part of a smart grid research initiative.",
  "tags": [
    "HEMS",
    "MPC", 
    "Hybrid MPC",
    "DNN",
    "LSTM",
    "Energy Optimization",
    "Smart Grid",
    "Battery Storage",
    "Heat Pump Control",
    "Python",
    "Time Series Forecasting",
    "Research"
  ],
  "githubLink": "https://github.com/Muckthebuck/2023-Energy-kit"
},
{
  "id": "AI_PB-AI-game-agent",
  "title": "CACHEX AI Agent – Adversarial Search for Game Strategy",
  "description": "An advanced AI agent for CACHEX (a HEX-like connection game) built using adversarial search techniques, including Minimax with Alpha-Beta pruning and heuristic path planning.",
  "fullDescription": "# CACHEX AI Agent – Adversarial Search for Game Strategy\n\nThis project implements a competitive AI agent for CACHEX, a modified version of the HEX board game. The agent leverages adversarial search algorithms and adaptive heuristics to play optimally across various board sizes and game states.\n\n### 🎯 Key Features\n- **Minimax Algorithm** with Alpha-Beta pruning for efficient state evaluation\n- **Forward Pruning** to reduce unnecessary branching and improve depth\n- **Heuristic Evaluation Functions** balancing path completion, blocking, and connection density\n- **Weighted A*** for optimal path estimation in dynamic environments\n- **Adaptive Depth Strategy**: dynamically adjusts Minimax depth based on board size and game stage\n- Supports capture mechanics and aggressive vs. defensive strategy balancing\n\n### 🧠 Performance Highlights\n- Achieved a **98%+ win rate** over 500+ simulated games across board sizes 3×3, 5×5, 7×7, and 8×8\n- Capable of real-time decision-making with tight time limits\n\nThis project demonstrates the effectiveness of hybrid search and planning techniques in adversarial board games.",
  "tags": [
    "Game AI",
    "Adversarial Search",
    "Minimax Pruning",
    "Alpha-Beta Pruning",
    "Heuristics",
    "A* Search",
    "AI Agent",
    "Python",
    "Graph Algorithms",
    "Artificial Intelligence",
    "Search Algorithms"
  ],
  "githubLink": "https://github.com/Muckthebuck/AI_PB-AI-game-agent",
  "paperLink": "https://github.com/Muckthebuck/AI_PB-AI-game-agent/blob/main/COMP30024_PROJECT_PARTB_REPORT.pdf",
  "bannerImage": "/images/triplets.png"
},
{
  "id": "Cerce",
  "title": "MBSI CereCe Project (formerly Cerebruh)",
  "description": "Project CereCe empowers self-directed mobility for individuals with tetraplegia by integrating gaze-tracking and brain-computer interface (BCI) technologies.",
  "fullDescription": "**Project CereCe** aims to empower **self-directed mobility** for individuals with **tetraplegia** by integrating **gaze-tracking** and **brain-computer interface (BCI)** technologies into a unified control system for assistive devices, such as wheelchairs.\n\nCurrently in its **research and prototyping phase**, this project is being conducted in collaboration with mentors from the **University of Melbourne** and is sponsored by **MentaLab**.\n\n### My Role: Integration Team Lead\n\nAs the **Integration Team Lead**, I was responsible for bridging the efforts of the BCI and computer vision teams to deliver a functional, testable prototype. My key contributions included:\n\n- 🧠 Integrating BCI and gaze-tracking systems into a seamless control system  \n- 🧩 Designing and implementing the system's **software architecture**  \n- 🔍 Conducting background research and building early-stage **miniature prototypes**  \n- 🤝 Coordinating between cross-functional teams to ensure system reliability  \n- 🧑‍🏫 Leading internal **tech workshops** on:\n  - Object-Oriented Programming (OOP)\n  - Development tools like **VS Code** and **GitHub**\n- 🛠️ Setting up the organization’s GitHub structure and promoting **industry-standard practices** for effective collaboration\n\nWhile still in its early stages, **CereCe** holds immense potential to improve quality of life by enabling hands-free, intuitive control for individuals with severe mobility limitations.\n\n🔗 [Follow the project on Instagram →](https://www.instagram.com/mbsi_projectcerece/)",
  "tags": [
    "Brain Computer Interface (BCI)",
    "Gaze Tracking",
    "Computer Vision",
    "Assistive Technology",
    "Robotics",
    "Python",
    "Research",
    "Integration"
  ],
  "link": "https://www.instagram.com/mbsi_projectcerece/"
},
{
  "id": "ChikiDeliveryService",
  "title": "Chiki’s Delivery Service - Casual 3D Platformer",
  "description": "Chiki’s Delivery Service is a casual 3D platformer featuring a charming chicken protagonist delivering packages across procedurally generated levels, emphasizing simple controls, physics-based gameplay, and replayability through timed challenges and medals.",
  "fullDescription": "**Chiki’s Delivery Service** is a casual 3D platformer developed using **Unity**, where players control Chiki, an aspiring delivery chick tasked with navigating various obstacle-filled, procedurally generated levels to deliver packages quickly and efficiently.\n\nThe game focuses on approachable gameplay mechanics such as jumping, gliding, and physics-based package handling, enhanced by a medal system to encourage replayability and mastery.\n\n### My Role: Gameplay Designer & Level Designer\n\nAs part of the core development team, I contributed extensively by:\n\n- 🎮 Designing and implementing core **gameplay mechanics** including player movement, package delivery, and the medal reward system\n- 🌍 Leading the **procedural generation** of terrains and maps to ensure varied and engaging level layouts. Created an algorithm inspired by Wave function collapse which solves constraint satisfaction problem on 3D grid.\n- 🏗️ Collaborating on **level design** with the team to integrate verticality, obstacles, and pacing that balance challenge with fun\n- 📖 Developing **storytelling elements and gameplay objectives** to deepen player engagement\n- 📦 Managing **game assets and organization** to ensure cohesive visual and gameplay experience\n- 🧪 Conducting **playtesting and surveys** to collect player feedback and guide iterative improvements\n\nI also maintained regular communication with other teams — physics, animation, shaders, and sound — to ensure smooth system integration. Progress was tracked through weekly meetings and documentation using Confluence.",
  "tags": [
    "Unity",
    "Procedural Generation",
    "Level Design",
    "Gameplay Design",
    "3D Platformer",
    "HLSL",
    "Physics",
    "Playtesting",
    "Wave Function Collapse",
    "3D Modelling"
  ],
  "githubLink": "https://github.com/Kaobara/TeaStainStudiosUnityProject",
  "bannerImage": "/images/chiki.gif"
},
{
  "id": "MelbourneTelescopeProject",
  "title": "Great Melbourne Telescope Restorative Project",
  "description": "Contributed to the restoration of the Great Melbourne Telescope by developing an interactive Star Map interface and streamlining the development environment.",
  "fullDescription": "As a **Software Engineer Intern** on the Melbourne Telescope Restorative Project at **Museums Victoria**, I focused on enhancing user experience and development workflows for the Great Melbourne Telescope’s digital interface.\n\nKey contributions included:\n\n- ⭐ Developed an interactive **Star Map interface** using **Django**, **Vue.js**, and **C++**, enabling users to navigate the night sky intuitively\n- 🐳 Introduced **Docker** to simplify and standardize development and deployment processes across the team\n- 🛠️ Automated environment setup and deployment tasks through **Bash scripting**, significantly boosting developer productivity and reducing onboarding time\n\nThis internship spanned from **March to June 2024** and provided valuable experience in full-stack development, cross-language integration, and DevOps automation.",
  "tags": [
    "Django",
    "Vue.js",
    "C++",
    "Docker",
    "Bash",
    "WASM",
    "Frontend",
    "DevOps",
    "Internship",
    "WebGL",
    "C"
  ],
  "link": "https://museumsvictoria.com.au/scienceworks/whats-on/great-melbourne-telescope-restoration/"
},
{
  "id": "BCI_MS_FeasibilityStudy",
  "title": "Feasibility of Source-Level BCI for Users with Multiple Sclerosis (MS)",
  "description": "This study explores the feasibility of using source-level EEG analysis for Brain-Computer Interface (BCI) applications in individuals with Multiple Sclerosis (MS).",
  "fullDescription": "**This research** evaluates the potential of source-level Brain-Computer Interface (BCI) systems for individuals with **Multiple Sclerosis (MS)** using previously recorded EEG data.\n\nThe study analyzed motor imagery EEG signals from **eight participants**—one with MS and seven neurotypical controls—focusing on imagined left and right-hand movements. Using **equivalent current dipole (ECD) cluster fitting**, the research localized brain activity to the **motor cortices** and compared spatial patterns between the MS and control groups.\n\n### Key Findings:\n- 🧠 Dipole sources were successfully localized to **motor cortices** across all participants.\n- ⚡ Notable **spatial differences** were observed between the MS participant and controls, though core motor areas were still activated.\n- 📉 **Reduced alpha power** was found in the MS participant during motor imagery, suggesting altered cortical activation.\n- 🧩 **Beta-band power** showed potential as a distinguishing feature between imagined left and right-hand movements for users with MS.\n\n### Clinical Relevance:\nThis work provides a **proof of concept** that **BCI systems** can be adapted for users with MS, contributing toward **accessible, user-specific assistive technologies** for individuals with motor impairments.\n\n🔗 [View Publication →](https://ieeexplore.ieee.org/document/10340364)",
  "tags": [
    "Brain Computer Interface (BCI)",
    "EEG",
    "Motor Imagery",
    "Multiple Sclerosis",
    "Neuroengineering",
    "Source-Level Analysis",
    "Alpha Power",
    "Beta Band",
    "Dipole Fitting",
    "Assistive Technology",
    "Localisation",
    "Research",
    "Internship"
  ],
  "paperLink": "https://ieeexplore.ieee.org/document/10340364",
  "bannerImage": "/images/SMDipoleDensity.png"
},
{
  "id": "OphthalmodynamometryDevice",
  "title": "Non-Invasive Intracranial Pressure Measurement Device Prototype",
  "description": "Explored a cost-effective and simplified method for non-invasive intracranial pressure estimation through early-stage prototyping and component research.",
  "fullDescription": "As a **Research Engineer** at the **John Neuro Bionics Lab** (University of Melbourne), I worked on a feasibility study to explore a simplified and low-cost method for **Ophthalmodynamometry**—a non-invasive technique for estimating **intracranial pressure (ICP)** by observing eye pressure and retinal vessel pulsation.\n\nThe goal was to investigate whether a basic device could be built using inexpensive components to replace current systems that require two specialists and expensive setups.\n\n### Key Contributions:\n- 🛠️ Built an **early-stage hardware prototype** using a **pressure sensor**, **green LED**, and **sensor arrays** to simulate eye pressure application and retinal observation\n- 🔍 Conducted research into **cost-effective hardware components** and system configurations suitable for future development\n- ⚙️ Explored practical design considerations for a **portable, single-operator setup**, focusing on hardware feasibility\n- 📉 Demonstrated the basic **viability of a simplified system**, laying groundwork for further development and signal processing integration by the broader team\n\nThis work served as a **proof of concept** that a compact and affordable Ophthalmodynamometry device could be developed for use in clinical or field environments, particularly in resource-constrained settings.",
  "tags": [
    "Medical Device",
    "Intracranial Pressure",
    "Ophthalmodynamometry",
    "MATLAB",
    "Python",
    "C++",
    "Biomedical Engineering",
    "Signal Processing",
    "Embedded & Hardware",
    "Research"
  ],
  "link": "https://biomedical.eng.unimelb.edu.au/john-neurobionics"
},

{
  "id": "PhongShaderWorkshop",
  "title": "Lighting & Shading in Unity – Phong Illumination Model (Cg/HLSL)",
  "description": "Explored lighting models in Unity using Cg/HLSL shaders, focusing on Phong and Gouraud shading techniques through the rendering pipeline.",
  "fullDescription": "This workshop involved investigating and implementing the **Phong illumination model** in Unity using custom shaders written in **Cg/HLSL**. The focus was on understanding how lighting is computed at different stages of the **rendering pipeline**, including **per-vertex (Gouraud)** and **per-fragment (Phong)** shading.\n\n### Key Tasks:\n- 💡 Analyzed and debugged an incomplete **Gouraud shader** to correctly implement Phong lighting at the vertex level\n- 🎮 Worked with Unity scene files such as `MainScene.unity` and custom C# scripts like `GenerateCube.cs` (for mesh and normals) and `PointLight.cs` (for light data)\n- 🧠 Gained hands-on understanding of **shader pipeline stages** and how illumination changes based on where in the pipeline it's computed\n- 🖥️ Compared visual differences between **Gouraud** and **Phong** shading to understand trade-offs in visual fidelity and performance\n\nThis workshop deepened my knowledge of **real-time rendering**, **lighting models**, and low-level **GPU programming** within the Unity engine.",
  "tags": [
    "Unity",
    "Shaders",
    "Cg",
    "HLSL",
    "Phong Shading",
    "Gouraud Shading",
    "Graphics Pipeline",
    "Rendering",
    "Computer Graphics",
    "Lighting Models"
  ],
  "githubLink": "https://github.com/Muckthebuck/Workshop-8"
},

{
  "id": "VoronoiDiagramC",
  "title": "Voronoi Diagram Generator in C",
  "description": "Implemented a Voronoi diagram generator in C using a bounding polygon and centroid data (watchtower points) as input.",
  "fullDescription": "**VoronoiDiagram** is a C-based implementation that generates a **Voronoi diagram** given an initial **bounding polygon** and a set of **centroid data points** (referred to as *watchtower points*).\n\nThe program constructs Voronoi cells such that each point in a cell is closer to its associated watchtower than to any other. It respects polygonal boundaries, ensuring all generated regions are clipped within a user-defined area.\n\n### Key Features:\n- 🗺️ Accepts **polygonal boundaries** as constraints for the generated diagram\n- 🛰️ Takes **centroid/watchtower coordinates** as input\n- 📐 Computes and constructs **Voronoi cells** using geometric algorithms\n- 🧮 Written entirely in **C**, focusing on performance and low-level memory management\n\nThis project demonstrates proficiency in **computational geometry**, **spatial partitioning**, and **geometric data structures**, with real-world applications in mapping, environmental monitoring, and cellular network planning.",
  "tags": [
    "Voronoi Diagram",
    "C",
    "Computational Geometry",
    "Geometric Algorithms",
    "Polygon Clipping"
  ],
  "githubLink": "https://github.com/Muckthebuck/Voronoi-Diagram",
  "bannerImage":"/images/voronoi.png"
},
{
  "id": "DCELPartitioning",
  "title": "DCEL-Based Polygon Partitioning System in C",
  "description": "Implemented a DCEL data structure in C to support geometric space partitioning, including cutting convex polygons, for regional analysis based on watchtower data.",
  "fullDescription": "This project involved building a **Doubly Connected Edge List (DCEL)** in **C** to represent and manipulate **polygonal subdivisions** within a given bounding area, designed for a bushfire-planning scenario in **Victoria, Australia**.\n\nThe primary goal was to associate **watchtower locations** with spatial regions and evaluate **population coverage** across postcode areas, supporting dynamic geometric operations such as cutting regions in response to user interaction or policy needs.\n\n### Key Features:\n- 🧱 Implemented a fully functional **DCEL data structure** to represent planar graphs and polygonal faces\n- ✂️ Supported **cut operations** that allowed splitting **convex polygons** into two valid sub-regions while maintaining DCEL integrity\n- 🛰️ Processed **watchtower point data** and **postcode population data** for spatial querying and region assignment\n- 🧭 Enabled user-driven **polygon editing** to assess how territorial changes affect coverage\n- ⚙️ Written entirely in **C**, with attention to memory safety and efficient pointer-based manipulation\n\nThis project showcased the ability to apply advanced data structures to **real-world spatial partitioning problems**, laying groundwork for applications in **GIS**, **planning**, and **computational geometry**.",
  "tags": [
    "Doubly Connected Edge List (DCEL)",
    "C",
    "Computational Geometry",
    "Polygon Cutting",
    "Geometric Data Structures"
  ],
  "githubLink": "https://github.com/Muckthebuck/Alg_data_struct_ass1_DCEL/tree/main",
  "bannerImage": "/images/dcel.png"
},
{
  "id": "GNS3RoutingExploration",
  "title": "Exploration of Internet Routing using GNS3",
  "description": "A hands-on exploration and comparative analysis of Internet routing protocols using GNS3 and FRRouting, focused on RIP, OSPF, and EIGRP under various simulated network scenarios.",
  "fullDescription": "**Exploration of Internet Routing using GNS3** is a research and simulation-based project that investigates the behaviour, performance, and design principles of major Internet routing protocols—**RIP**, **OSPF**, and **EIGRP**—through hands-on experimentation.\n\nLeveraging **GNS3 (Graphical Network Simulator-3)** and **FRRouting (FRR)**, we created small-scale virtual networks and observed protocol behaviour using tools like **Wireshark**. Through carefully crafted experiments, we analysed **routing convergence**, **efficiency**, and **scalability** under various conditions, such as link failures and changes in link cost.\n\n### Project Objectives:\n1. 🧭 Compare the functionality and characteristics of **RIP**, **OSPF**, and **EIGRP** across topologies\n2. ⏱️ Measure and analyse **convergence time**, **efficiency**, and **protocol overhead**\n3. 🧠 Explore strengths, weaknesses, and suitable use-cases for each protocol\n4. 🛠️ Gain hands-on experience with **GNS3**, **FRRouting**, and **Wireshark** for network simulation and diagnostics\n\n### Technical Highlights:\n- Implemented multiple simulated topologies to test protocol behaviour\n- Used **graph theory** concepts and algorithms like **Dijkstra’s**, **Bellman-Ford**, and **Diffusing Update Algorithm** to inform theoretical background\n- Visualised protocol message exchange using **Wireshark packet capture**\n- Simulated **failure scenarios** to observe protocol robustness and adaptability\n\nThis project bridged theoretical networking knowledge with practical, scenario-driven insights—building core competencies in network design, troubleshooting, and routing architecture evaluation.",
  "tags": [
    "Networking",
    "Routing",
    "GNS3",
    "FRRouting",
    "OSPF",
    "EIGRP",
    "RIP",
    "Wireshark",
    "Graph Theory",
    "Dijkstra's Algorithm",
    "Bellman-Ford Algorithm"
  ],
  "githubLink": "https://github.com/Muckthebuck/Exploration-of-Internet-Routing-using-GNS3",
  "paperLink": "https://github.com/Muckthebuck/Exploration-of-Internet-Routing-using-GNS3/blob/main/ELEN90061_LDI_Project.pdf"
},
{
  "id": "SpeechHMM",
  "title": "Speech Recognition with Hidden Markov Models (HMM)",
  "description": "A speech recognition system that classifies spoken food-related words using Hidden Markov Models and MFCC feature extraction.",
  "fullDescription": "**Speech Recognition with Hidden Markov Models** is a machine learning project focused on building a voice-based classifier that identifies spoken instances of daily food-related words such as “Rice”, “Pizza”, “Burger”, “Sandwich”, “Sausage”, “Meatball”, and “Spaghetti”.\n\nThe recognizer uses **Mel-Frequency Cepstral Coefficients (MFCC)** to extract features from speech audio and then applies **Hidden Markov Models (HMMs)**—trained via the **Baum-Welch algorithm**—to classify input speech signals.\n\n### Key Project Steps:\n- **Data Preparation**: Curated and recorded speech samples for seven distinct food-related words. Divided data into training and testing sets.\n- **Feature Extraction**: Implemented MFCC-based feature extraction to transform raw audio into meaningful signal representations.\n- **Model Training**: Trained individual HMMs for each word using the Baum-Welch algorithm (an Expectation-Maximization approach).\n- **Model Evaluation**: Classified test audio by selecting the HMM that best fits the input sequence.\n\n### Advanced Exploration:\n- Investigated the impact of hyperparameters (number of MFCCs, hidden states, and observation symbols) on model performance.\n- **Bonus Analysis**: Compared HMM performance with alternate classifiers like SVM, Naive Bayes, and Neural Networks, discussing the pros and cons of EM-based HMM training versus discriminative approaches.\n\nThis project offered a comprehensive, end-to-end introduction to speech signal processing, HMM-based modeling, and practical challenges in acoustic classification.",
  "tags": [
    "Speech Recognition",
    "Hidden Markov Models",
    "MFCC",
    "Machine Learning",
    "Baum-Welch",
    "Signal Processing",
    "Python"
  ],
  "githubLink": "https://github.com/Muckthebuck/Speech-Recognition-with-Hidden-Markov-Models",
  "paperLink": "https://github.com/Muckthebuck/Speech-Recognition-with-Hidden-Markov-Models/blob/main/report.pdf"
},

{
  "id": "RayTracerCOMP30019",
  "title": "Ray Tracer - Graphics & Interaction",
  "description": "A CPU-based recursive ray tracer implemented in C#, featuring advanced rendering techniques including shadows, reflections, refractions, and OBJ model loading.",
  "fullDescription": "This project is a comprehensive CPU-based ray tracer developed for the subject COMP30019: Graphics and Interaction. The ray tracer was built from scratch in C# and supports a range of physically-based rendering techniques through multiple stages of development.\n\n### Key Features:\n- **Stage 1: Core Rendering Pipeline**\n  - Vector mathematics implementation\n  - Ray casting per pixel\n  - Ray-object intersection tests (spheres, planes, triangles)\n  - Solid color shading based on object types\n\n- **Stage 2: Lighting and Materials**\n  - Diffuse lighting using Lambertian reflection\n  - Shadow rays for realistic occlusion\n  - Reflective materials with recursive ray tracing up to a max depth of 10\n  - Refractive materials using Snell’s law and Fresnel equations\n  - Anti-aliasing with super-sampling techniques\n\n- **Stage 3: Advanced Extensions**\n  - **OBJ Model Support**: Parses .obj files into triangle meshes and uses bounding sphere hitboxes for efficient intersection checks, significantly improving render performance.\n  - **Custom Camera Orientation**: Implements Rodrigues’ rotation formula to rotate camera rays, supporting arbitrary view orientations.\n\n### Implementation Notes:\n- Employed a left-handed coordinate system and carefully adjusted vector operations and parsing to maintain consistent orientation.\n- Significant optimizations were made, including bounding spheres for complex geometry, which reduced rendering time from 30 minutes to under 3 minutes (without supersampling).\n- Anti-aliasing experiments included recursive adaptive sampling and static supersampling using multiple sub-pixels per pixel.\n\n### Render Example:\n- Final scene rendered using OBJ models, custom camera orientation, and all lighting features enabled.\n- Render command:\n  ```\n  dotnet run -- -f tests/final_scene.txt -o images/final_scene.png -x 4 --cam-pos -3,0,-2 --cam-angle 30 --cam-axis 0,1,0\n  ```",
  "tags": [
    "Ray Tracing",
    "Computer Graphics",
    "Rendering",
    "C#",
    "OBJ Model Support",
    "Fresnel Effect",
    "Snell's Law",
    "Shadows",
    "Reflection & Refraction",
    "Anti-Aliasing",
    "Custom Camera Orientation"
  ],
  "link": "https://github.com/Muckthebuck/Ray-Tracer"
},
{
  "id": "pattern-occurrence-mdp",
  "title": "Pattern Occurrence in Markov Chains & Traffic MDPs",
  "description": "Explores pattern detection in Markov chains and reinforcement learning for traffic control using MDPs.",
  "fullDescription": "This project addresses three advanced problems involving **Markov Chains**, **Pattern Occurrence Detection**, and **Reinforcement Learning for Traffic Simulation**. It blends theoretical probability, linear algebra, and simulation-based methods with practical coding implementations to analyze complex stochastic systems. This homework set is from Prof. Soojean Han's EE448F: Learning Patterns for Autonomous Control, conducted at the Autonomous Control for Stochastic Systems (ACSS) Lab.\n\n### Problem 1: Pattern Occurrence in a Markov Chain (Martingale Method)\nComputed the expected minimum occurrence time (E[τ]) and first-occurrence probabilities ({qₖ}) for a set of patterns in a 5-state Markov chain using martingale-based techniques and linear matrix equations.\n\n### Problem 2: Alternative Agent Design for Pattern Detection\nProposed new constructions for betting strategies and agent design in the pattern occurrence framework, including:\n- Augmentation with a single prefix state\n- Direct mapping of betting strategies based on observed endings\n- Implemented and compared expected times and probabilities with Problem 1\n\n### Problem 3: Traffic Simulation as a Markov Decision Process\nSimulated a 4-way traffic intersection as an MDP and applied RL algorithms:\n- Defined state, action, transition, and reward components\n- Implemented Q-learning/SARSA over 300 seconds\n- Introduced memory-augmented RL to cache and reuse optimal actions\n- Evaluated results using wait time and vehicle throughput metrics (VC(t))",
  "tags": [
    "Markov Chains",
    "Pattern Detection",
    "Martingales",
    "Markov Decision Processes",
    "Q-Learning",
    "Research",
    "Python"
  ],
  "githubLink": "https://github.com/Muckthebuck/Pattern-Occurrence-problems---MDP-and-RL/tree/main"
},
{
  "id": "feedback-gathering-symmetry",
  "title": "Feedback Data-Gathering & Symmetry in Classical Mechanics",
  "description": "Simulates NF/FB sensor architectures and proves energy/momentum conservation via Noether’s theorem.",
  "fullDescription": "This project investigates feedback-based distributed data-gathering architectures and explores fundamental symmetry principles in physics. It combines coding-based simulation of feedback vs. non-feedback systems and analytical proofs in classical mechanics rooted in Noether’s theorem.\n\nThis Homework Set is from Prof. Soojean Han's EE448F: Learning Patterns for Autonomous Control, KAIST.\n\n### Problem 1: Feedback Distributed Data-Gathering — Simulations\nSimulates both NF and FB architectures with probabilistic broadcasting, smarter triggering, and variable thresholds. The architecture was introduce by SooJean Han et. al in https://doi.org/10.48550/arXiv.2208.06395 . Key experiments:\n- Sample-path plots of transmission & estimation\n- Monte Carlo evaluation of MSE & power\n- Trade-off analysis with varying thresholds and broadcast probabilities\n- High-dimensional extension (n = 20, M = 5 sensors)\n- Strategy design for optimal FB performance\n\n### Problem 2: Rotation Symmetry in 3D\nGeneralizes angular momentum conservation from 2D to 3D using Noether’s theorem.\n\n### Problem 3: Noether’s Theorem — Time Translation Symmetry\nProves energy conservation using:\n- Lagrangian formulation with Taylor expansion & integration-by-parts\n- Time-dependent Lagrangian counterexamples\n- Hamiltonian mechanics and variational analysis",
  "tags": [
    "Distributed Systems",
    "Sensor Fusion",
    "Sensor Networks",
    "Noether's Theorem",
    "Lagrangian Mechanics",
    "Hamiltonian Mechanics",
    "Energy Conservation",
    "Monte-Carlo Trials",
    "Symmetry",
    "Python",
    "Research"
  ],
  "githubLink": "https://github.com/Muckthebuck/Feedback-Distributed-Data-Gathering-and-symmetries"
},
{
  "id": "dual-memory-traffic-rl",
  "title": "Dual-Memory Integrated Learning: A Mulit-agent RL framework",
  "description": "Implements a novel dual-memory replay architecture for reinforcement learning applied to traffic congestion control.",
  "fullDescription": "Episodic control, inspired by the role of episodic memory in the human brain, has been shown to improve the sample inefficiency of model-free reinforcement learning by reusing high-return past experiences. However, the memory growth of episodic control is undesirable in large-scale multi-agent problems such as vehicle traffic management. This paper proposes a novel replay memory architecture called Dual-Memory Integrated Learning, to augment to multi-agent reinforcement learning methods for congestion control via adaptive light signal scheduling. Our dual-memory architecture mimics two core capabilities of human decision-making. First, it relies on diverse types of memory--semantic and episodic, short-term and long-term--in order to remember high-return states that occur often in the network and filter out states that don't. Second, it employs equivalence classes to group together similar state-action pairs and that can be controlled using the same action (i.e., light signal sequence). Theoretical analyses establish memory growth bounds, and simulation experiments on several intersection networks showcase improved congestion performance (e.g., vehicle throughput) from our method.",
  "tags": [
    "Multi-Agent Reinforcement Learning (MARL)",
    "Traffic Control",
    "Replay Memory",
    "Episodic Memory",
    "Semantic Memory",
    "Equivariance",
    "State Abstraction",
    "Congestion Control",
    "Monte-Carlo Trials",
    "Research",
    "Python"
  ],
  "githubLink": "https://github.com/kvnoct/episodic_control",
  "paperLink": "https://arxiv.org/abs/2407.16034",
  "bannerImage": "/images/multi_agent_framework.svg"
}



]
